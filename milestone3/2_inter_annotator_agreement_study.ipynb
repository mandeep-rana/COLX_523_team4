{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interannotator Agreement Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure: Although we explored both kappa and pi, our team agreed that pi would be a good measure as it takes into account because the assumption for S, which is that all coders annotation have a uniform distribution, if not likely true in our case. Moreover, the crowdsourcing nature of Mechanical Turk makes evaluating using kappa not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import json\n",
    "from nltk.metrics.agreement import AnnotationTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2annotation_dict(fname):\n",
    "    annotated=pd.read_csv(fname)\n",
    "    annotated=annotated.to_dict('records')\n",
    "    blank_annotation={'Content':defaultdict(lambda: defaultdict(list)),\n",
    "                      'Course delivery':defaultdict(lambda: defaultdict(list)),\n",
    "                      'Difficulty':defaultdict(lambda: defaultdict(list)),\n",
    "                      'Workload':defaultdict(lambda: defaultdict(list)),\n",
    "                      'Usefulness':defaultdict(lambda: defaultdict(list))}\n",
    "    for i in annotated:\n",
    "        identified_facets=json.loads(i['Answer.taskAnswers'])[0]['category']['labels']\n",
    "        for facet in blank_annotation.keys():#initialize all to False by default\n",
    "            blank_annotation[facet][i['HITId']][i['WorkerId']]='F'\n",
    "        for identified in identified_facets:\n",
    "            blank_annotation[identified][i['HITId']][i['WorkerId']]='T'\n",
    "    return blank_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2triplets(annotation_of_HITId):\n",
    "    trips=[]\n",
    "    for HITId in annotation_of_HITId.keys():\n",
    "        ann_work=annotation_of_HITId[HITId]\n",
    "        ann_val=list(ann_work.values())\n",
    "        for worker_idx in range(len(ann_val)):\n",
    "            trips.append(('C{}'.format(worker_idx),HITId,ann_val[worker_idx]))\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_3(trips):\n",
    "    agg=defaultdict(int)\n",
    "    for rec in trips:\n",
    "        agg[rec[1]]+=1\n",
    "    l3=[i[0] for i in agg.items() if i[1]==3]\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pi(blank_annotation):\n",
    "    Facet_pi={}\n",
    "    for Facet in blank_annotation.keys():\n",
    "        trips=convert2triplets(blank_annotation[Facet])\n",
    "        l3=find_3(trips)\n",
    "        trips_f=[i for i in trips if i[1] in l3] \n",
    "        annotation_task = AnnotationTask(trips_f)\n",
    "        Facet_pi[Facet]=annotation_task.pi()\n",
    "    return Facet_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kp(blank_annotation):\n",
    "    Facet_pi={}\n",
    "    for Facet in blank_annotation.keys():\n",
    "        trips=convert2triplets(blank_annotation[Facet])\n",
    "        l3=find_3(trips)\n",
    "        trips_f=[i for i in trips if i[1] in l3] \n",
    "        annotation_task = AnnotationTask(trips_f)\n",
    "        Facet_pi[Facet]=annotation_task.kappa()\n",
    "    return Facet_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_sampled_reviews_annotated=calculate_pi(convert2annotation_dict('sampled_reviews_annotated.csv'))\n",
    "pi_sampled_review_annotated_0=calculate_pi(convert2annotation_dict('sampled_review_annotated_0.csv'))\n",
    "pi_sampled_review_annotated_1=calculate_pi(convert2annotation_dict('sampled_review_annotated_1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_sampled_reviews_annotated=calculate_kp(convert2annotation_dict('sampled_reviews_annotated.csv'))\n",
    "kp_sampled_review_annotated_0=calculate_kp(convert2annotation_dict('sampled_review_annotated_0.csv'))\n",
    "kp_sampled_review_annotated_1=calculate_kp(convert2annotation_dict('sampled_review_annotated_1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': -0.06944444444444459,\n",
       " 'Course delivery': -0.14230769230769238,\n",
       " 'Difficulty': 0.292857142857143,\n",
       " 'Workload': -0.018518518518518705,\n",
       " 'Usefulness': -0.004347826086956478}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_sampled_reviews_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': -0.21008403361344544,\n",
       " 'Course delivery': -0.10052910052910057,\n",
       " 'Difficulty': -0.23076923076923078,\n",
       " 'Workload': 0.0,\n",
       " 'Usefulness': -0.22222222222222232}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_sampled_review_annotated_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': -0.008403361344537785,\n",
       " 'Course delivery': -0.11111111111111101,\n",
       " 'Difficulty': -0.20000000000000007,\n",
       " 'Workload': -0.14285714285714285,\n",
       " 'Usefulness': -0.2187500000000001}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_sampled_review_annotated_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': -0.06560187216615483,\n",
       " 'Course delivery': -0.09308775731310952,\n",
       " 'Difficulty': 0.24806201550387597,\n",
       " 'Workload': 0.0013506098847759402,\n",
       " 'Usefulness': 0.04323827478345696}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_sampled_reviews_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': -0.20839160839160842,\n",
       " 'Course delivery': -0.0900537634408602,\n",
       " 'Difficulty': -0.1472261072261072,\n",
       " 'Workload': 0.023833309547595254,\n",
       " 'Usefulness': -0.2185909328766472}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_sampled_review_annotated_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': 0.03857907112017762,\n",
       " 'Course delivery': -0.10974739546168118,\n",
       " 'Difficulty': -0.1624288865668176,\n",
       " 'Workload': -0.12360931833548468,\n",
       " 'Usefulness': -0.12087628200160168}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_sampled_review_annotated_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_full_reviews_annotated=calculate_pi(convert2annotation_dict('reviews_full_annotated.csv'))\n",
    "kp_full_reviews_annotated=calculate_kp(convert2annotation_dict('reviews_full_annotated.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': -0.05073439412484699,\n",
       " 'Course delivery': 0.07680593889787751,\n",
       " 'Difficulty': 0.08123172870785426,\n",
       " 'Workload': 0.02020202020202022,\n",
       " 'Usefulness': 0.05876010781671176}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Our final result\n",
    "pi_full_reviews_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': -0.050426254188860764,\n",
       " 'Course delivery': 0.07705805314453486,\n",
       " 'Difficulty': 0.0812049889045453,\n",
       " 'Workload': 0.0203497054778624,\n",
       " 'Usefulness': 0.05875687152163197}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp_full_reviews_annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interannotator Study - Discussion\n",
    "\n",
    "## How reliable is the annotation?\n",
    "It is not very reliable due to the nature of crowd sourcing approach as well as the nature of the task. Some factors that may have reduced the reliability of the annotation:\n",
    "- We cannot guarantee the annotation was done after completely reading and understanding the instruction given.\n",
    "- Annotation labels are general. Although our intention is to capture the general aspects mentioned in the course reviews, this kind of generality makes annotation prone to subjectivity.\n",
    "\n",
    "## What can be done to improve?\n",
    "With enough time, it is best to train individual annotators on the task to ensure annotation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
