{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import sqlite3\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import hashlib\n",
    "#regex for extracting decimals from https://stackoverflow.com/questions/12117024/decimal-number-regular-expression-where-digit-after-decimal-is-optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_table=\"\"\"CREATE TABLE if not exists \"courses\" (\n",
    "\t\"url\"\tTEXT UNIQUE,\n",
    "\t\"title\"\tTEXT,\n",
    "\t\"instructor\"\tTEXT,\n",
    "\t\"average_rating\"\tREAL,\n",
    "\t\"total_pages\"\tINTEGER,\n",
    "\t\"scraped_pages\"\tINTEGER,\n",
    "\tPRIMARY KEY(\"url\")\n",
    ");\"\"\"\n",
    "\n",
    "reviews_table=\"\"\"\n",
    "CREATE TABLE if not exists \"reviews\" (\n",
    "\t\"id\"\tTEXT UNIQUE,\n",
    "\t\"course_url\"\tINTEGER,\n",
    "\t\"reviewer\"\tTEXT,\n",
    "\t\"review_date\"\tTEXT,\n",
    "\t\"review_unix\"\tREAL,\n",
    "\t\"helpful_count\"\tINTEGER,\n",
    "\t\"rating\"\tREAL,\n",
    "\t\"review\"\tINTEGER,\n",
    "\tPRIMARY KEY(\"id\")\n",
    ");\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_db():\n",
    "    conn=sqlite3.connect('d.db')\n",
    "    cur=conn.cursor()\n",
    "    cur.execute(courses_table)\n",
    "    cur.execute(reviews_table)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "def scrape_course_main_page(course_url,cur,conn,debug=False):\n",
    "    html=requests.get(course_url).content\n",
    "    soup=BeautifulSoup(html)\n",
    "    instructor=soup.find('div',attrs={'class':'rc-BannerInstructorInfo'}).find('span').text.strip()\n",
    "    average_rating=soup.find('span',attrs={'class':'number-rating'}).text.strip()\n",
    "    average_rating=re.findall(r'\\d+\\.?\\d*',average_rating)[0]\n",
    "    title=soup.find('div',attrs={'class':'BannerTitle'}).find('h1').text.strip()\n",
    "    \n",
    "    review_html=requests.get(course_url+'/reviews').content\n",
    "    review_soup=BeautifulSoup(review_html)\n",
    "    pg_nav_bar=review_soup.find('nav',attrs={'aria-label':'Pagination Controls'}).findAll('span')\n",
    "    total_pages=int(pg_nav_bar[-2].text)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Course title: \",title)\n",
    "        print(\"Instructor: \",instructor)\n",
    "        print(\"Average course rating: \",average_rating)\n",
    "        print(\"Total pages: \",total_pages)\n",
    "    \n",
    "    cur.execute(\"update courses set title=?, instructor=?, average_rating=?, total_pages=? where url=?\", (title,instructor,average_rating,total_pages,course_url))\n",
    "    conn.commit()\n",
    "    \n",
    "def scrape_course_review(course_url,pgn,cur,conn,debug=False):\n",
    "    if pgn==400:\n",
    "        return#page 400 and after are not accessible\n",
    "    review_url=course_url+'/reviews?page={}'.format(pgn)\n",
    "    html=requests.get(review_url).content\n",
    "    soup=BeautifulSoup(html)\n",
    "    for review in soup.findAll('div',attrs={'class':'review-page-review'}):\n",
    "        helpful_count=review.find('button',attrs={'class':'review-helpful-button'}).text\n",
    "        helpful_count=re.findall(r'\\d+',helpful_count)\n",
    "        if helpful_count!=[]:\n",
    "            helpful_count=helpful_count[0]\n",
    "        else:\n",
    "            helpful_count=0\n",
    "        review_text=review.find('div',attrs={'class':'reviewText'}).text\n",
    "        reviewer=review.find('p',attrs={'class':'reviewerName'}).text.replace(\"By\",\"\").strip()\n",
    "        review_date=review.find('div',attrs={'class':'dateOfReview'}).text\n",
    "        review_timestamp=datetime.datetime.strptime(review_date,'%b %d, %Y').timestamp()\n",
    "        star_box=review.find('div',attrs={'role':'img'})\n",
    "        star_count=len(star_box.findAll('title',string='Filled Star'))\n",
    "        if debug:\n",
    "            print(\"Reviwer: \",reviewer)\n",
    "            print(\"Review Date: \",review_date)\n",
    "            print(\"Upvote: \",helpful_count)\n",
    "            print(\"Rating: \",star_count)\n",
    "            print(\"Review: \",review_text)\n",
    "        uid=review_url+reviewer+review_date+review_text\n",
    "        uid=hashlib.md5(uid.encode('utf-8')).hexdigest()\n",
    "        cur.execute(\"INSERT INTO reviews (id,course_url,reviewer,review_date,review_unix,helpful_count,rating,review) values (?,?,?,?,?,?,?,?) on CONFLICT(id) DO UPDATE SET  id=id\",(uid,course_url,reviewer,review_date,review_timestamp,helpful_count,star_count,review_text))\n",
    "        conn.commit()\n",
    "    cur.execute(\"update courses set scraped_pages=? where url=?\",(pgn,course_url))\n",
    "    conn.commit()\n",
    "    \n",
    "def scrape_course_list(pgn,cur,conn,debug=False):\n",
    "    list_url='https://www.coursera.org/search?query=free&page={}&index=prod_all_products_term_optimization'.format(pgn)\n",
    "    html=requests.get(list_url).content\n",
    "    soup=BeautifulSoup(html)\n",
    "    list_obj=json.loads(soup.find('script',attrs={'type':'application/ld+json'}).string)\n",
    "    for course in list_obj['itemListElement']:\n",
    "        cur.execute(\"INSERT INTO courses (url) Values (?) on CONFLICT(url) DO UPDATE SET  url=url\",(course['url'],))\n",
    "        conn.commit()\n",
    "        if debug:\n",
    "            print(course['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_course_meta_data(scrape_course_page=True,scrape_course_list=True,pages_of_courses=10):\n",
    "    initialize_db()\n",
    "    conn=sqlite3.connect('d.db')\n",
    "    cur=conn.cursor()\n",
    "    if scrape_course_list:\n",
    "        for i in range(1,pages_of_courses+1):\n",
    "            scrape_course_list(i,cur,conn)\n",
    "            time.sleep(5)\n",
    "    \n",
    "    if scrape_course_page:\n",
    "        for i in cur.execute(\"select url from courses where title is null\").fetchall():\n",
    "            course_url=i[0]\n",
    "            scrape_course_main_page(course_url,cur,conn)\n",
    "            time.sleep(5)\n",
    "        \n",
    "    cur.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reviews():\n",
    "    conn=sqlite3.connect('d.db')\n",
    "    cur=conn.cursor()\n",
    "    for i in cur.execute(\"select url,total_pages,scraped_pages from courses where total_pages is not null\").fetchall():\n",
    "        course_url,total_pages,scraped_pages=i\n",
    "        if total_pages==scraped_pages:\n",
    "            continue\n",
    "        if scraped_pages==None:\n",
    "            scraped_pages=0\n",
    "        for pgn in range(scraped_pages+1,total_pages+1):\n",
    "            if pgn>10:#only scrape 10 pages for each course to have some diversity\n",
    "                continue\n",
    "            scrape_course_review(course_url,pgn,cur,conn)\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
